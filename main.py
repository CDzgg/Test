# main.py
# ================= 1. å¯¼å…¥åŒº =================
import logging
import time
import json
import sys
import re
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# ç¬¬ä¸‰æ–¹åº“
try:
    from openai import OpenAI
    import pandas as pd
    import requests
    from tigeropen.common.util.signature_utils import read_private_key
    from tigeropen.tiger_open_config import TigerOpenClientConfig
    from tigeropen.common.consts import Language, QuoteRight
    from tigeropen.quote.quote_client import QuoteClient
    from tigeropen.trade.trade_client import TradeClient
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·è¿è¡Œ: pip install openai pandas requests tigeropen pandas_ta")
    sys.exit(1)

# æœ¬åœ°æ¨¡å—
try:
    import config
    from data_processor import MarketDataProcessor
except ImportError as e:
    print(f"âŒ ç¼ºå°‘æœ¬åœ°æ–‡ä»¶: {e}")
    sys.exit(1)

# ================= 2. å…¨å±€å˜é‡ä¸é…ç½® =================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("trade_bot.log", encoding='utf-8'),
        logging.StreamHandler(sys.stdout) 
    ],
    force=True 
)
logger = logging.getLogger()

# å…¨å±€å®¢æˆ·ç«¯å¯¹è±¡
tiger_client = None
tiger_trade_client = None
deepseek_client = None
WATCH_LIST = []
LAST_UPDATE_ID = 0
data_manager = None  # æ•°æ®ç®¡ç†å™¨å®ä¾‹

# ğŸ‘‡ğŸ‘‡ğŸ‘‡ SYSTEM PROMPT (æœ€ç»ˆå®Œæ•´ç‰ˆ) ğŸ‘‡ğŸ‘‡ğŸ‘‡
system_prompt = """
### Role Definition
ä½ æ˜¯ä¸€åç²¾é€šå¨ç§‘å¤«ç†è®ºï¼ˆWyckoff Methodï¼‰ã€é‡ä»·åˆ†æï¼ˆVPAï¼‰å’Œç»å…¸æŠ€æœ¯åˆ†æçš„è‚¡å¸‚çŸ­çº¿æ“ç›˜ä¸“å®¶ã€‚ä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯åˆ©ç”¨æŠ€æœ¯åˆ†ææ‰‹æ®µï¼Œæ•æ‰å¸‚åœºä¸­çš„ä¾›æ±‚å¤±è¡¡ç‚¹ï¼Œè·Ÿéšâ€œä¸»åŠ›èµ„é‡‘ï¼ˆSmart Money/Composite Manï¼‰â€çš„åŠ¨å‘ï¼Œä»¥æé«˜çš„çŸ­æœŸèƒœç‡è·å–è¶…é¢æ”¶ç›Šã€‚

### Data Input Explanation
ä½ å°†æ”¶åˆ°åŒ…å«ä»¥ä¸‹ä¸¤ç»„æ—¶é—´å‘¨æœŸçš„å¸‚åœºæ•°æ®ï¼š
1. **Intraday (5m)**: ç”¨äºæ•æ‰å¾®è§‚å…¥åœºç‚¹ã€çŸ­æœŸåŠ¨é‡ (RSI7, MACD Histogram) å’Œå³æ—¶è¶‹åŠ¿ (EMA20)ã€‚
2. **Long-term (4h)**: ç”¨äºåˆ¤æ–­å®è§‚è¶‹åŠ¿ç»“æ„ (EMA20/50)ã€é•¿æœŸåŠ¨é‡ (MACD) å’Œæ³¢åŠ¨ç‡é£æ§ (ATR3/14)ã€‚
3. **Market State**: åŒ…å«å®æ—¶ç›˜å£ä¸­é—´ä»· (Mid-price) å’ŒæŒä»“é‡ (Open Interest)ã€‚
4. **Data Sequence (CRITICAL)**: 
   - æ‰€æœ‰çš„ä»·æ ¼åˆ—è¡¨ï¼ˆå¦‚ price_sequence_last_60ï¼‰å‡ä¸¥æ ¼æŒ‰ç…§ **[æ—§ -> æ–°] (Chronological Order: Oldest to Newest)** çš„é¡ºåºæ’åˆ—ã€‚
   - åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´  (Last Element) ä»£è¡¨æœ€æ–°çš„å½“å‰ä»·æ ¼ã€‚

### Core Analysis Framework (Strict 5-Step)
åœ¨åˆ†æä»»ä½•æ ‡çš„æ—¶ï¼Œå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹äº”æ­¥åˆ†ææ³•ï¼Œå¹¶ç»“åˆåŒå‘¨æœŸæ•°æ®ï¼š

#### ç¬¬ä¸€æ­¥ï¼šå¤§å‘¨æœŸè¶‹åŠ¿å®šä½ (Long-term 4h Context)
- **è¶‹åŠ¿è¯†åˆ«**ï¼šåˆ©ç”¨ 4h EMA20 ä¸ EMA50 çš„å…³ç³»åˆ¤æ–­ä¸»è¶‹åŠ¿ï¼ˆå¤šå¤´æ’åˆ—/ç©ºå¤´æ’åˆ—ï¼‰ã€‚
- **æ³¢åŠ¨ç‡è¯„ä¼°**ï¼šå‚è€ƒ ATR14 è¯„ä¼°å½“å‰å¸‚åœºçš„é£é™©æ°´å¹³ã€‚

#### ç¬¬äºŒæ­¥ï¼šæ—¥å†…å¾®è§‚ç»“æ„ (Intraday 5m Structure)
- **åŠ¨é‡åˆ†æ**ï¼šè§‚å¯Ÿ 5m RSI7 çš„è¶…ä¹°è¶…å–æƒ…å†µï¼Œä»¥åŠ 5m MACD æŸ±çŠ¶å›¾çš„å˜åŒ–ï¼ˆåŠ¨èƒ½å¢å¼ºæˆ–å‡å¼±ï¼‰ã€‚
- **è¶‹åŠ¿è·Ÿéš**ï¼šæ£€æŸ¥ä»·æ ¼ç›¸å¯¹äº 5m EMA20 çš„ä½ç½®ã€‚

#### ç¬¬ä¸‰æ­¥ï¼šé‡ä»·å…³ç³»åˆ†æ (Volume-Price Analysis)
- **å¼‚å¸¸è¯†åˆ«**ï¼šå¯»æ‰¾é‡ä»·èƒŒç¦»ã€‚
- **ç¡®è®¤ä¿¡å·**ï¼šä»·æ ¼ä¸Šæ¶¨ä¼´éšæˆäº¤é‡æ”¾å¤§ã€‚

#### ç¬¬å››æ­¥ï¼šäº¤æ˜“å†³ç­–ä¸é£æ§ (Decision & Risk)
- **å…¥åœºä¿¡å·**ï¼šé•¿çº¿è¶‹åŠ¿å‘ä¸Š + çŸ­çº¿å›è°ƒåˆ°ä½ï¼ˆå¦‚RSI7è¶…å–ï¼‰æˆ–çªç ´ç¡®è®¤ã€‚
- **æ­¢æŸè®¾ç½®**ï¼šåˆ©ç”¨ 4h ATR3 è®¡ç®—ç´§å‡‘æ­¢æŸä½ã€‚

### Output Format (Markdown Report + JSON Summary)
è¯·æŒ‰ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºåˆ†ææŠ¥å‘Šï¼Œå¹¶åœ¨æœ€åé™„å¸¦ JSON Summaryï¼š

#### 1. ğŸ“Š åŒå‘¨æœŸè¶‹åŠ¿åˆ†æ
* **é•¿çº¿ç»“æ„ (4h)**: [æè¿° EMA20/50 å…³ç³»åŠå¤§è¶‹åŠ¿]
* **çŸ­çº¿åŠ¨èƒ½ (5m)**: [æè¿° RSI7 åŠ MACD çŠ¶æ€]

#### 2. ğŸ•¯ï¸ é‡ä»·ä¸ç›˜å£
* **å®æ—¶çŠ¶æ€**: [Mid-price åŠæŒä»“é‡åˆ†æ]
* **é‡ä»·ç‰¹å¾**: [åˆ†ææˆäº¤é‡é…åˆæƒ…å†µ]

#### 3. ğŸš€ äº¤æ˜“è®¡åˆ’
* **æ“ä½œå»ºè®®**: **[ä¹°å…¥ / å–å‡º / è§‚æœ›]**
* **å…¥åœºç†ç”±**: [ç»“åˆé•¿çŸ­å‘¨æœŸçš„é€»è¾‘]
* **æ­¢æŸå»ºè®®**: [åŸºäº ATR3 çš„å…·ä½“ä»·æ ¼]

---
**JSON_SUMMARY**:
{
  "action": "BUY" | "SELL" | "WAIT",
  "confidence": 0-100,
  "entry": float,
  "stop_loss": float,
  "reason": "ç®€çŸ­çš„ä¸­æ–‡ç†ç”±"
}
"""

# ================= 3. æ•°æ®ä¸ç¼“å­˜ç®¡ç†å™¨ =================

class MarketDataManager:
    def __init__(self, quote_client, ttl_seconds=60):
        self.client = quote_client
        self.ttl = ttl_seconds
        # ç»“æ„: { 'symbol': { 'quote': {data, ts}, '5min': {data, ts}, '240min': {data, ts} } }
        self._cache = {}

    def _get_from_cache(self, symbol, data_type):
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å‘½ä¸­ä¸”æœ‰æ•ˆ"""
        if symbol in self._cache and data_type in self._cache[symbol]:
            item = self._cache[symbol][data_type]
            if time.time() - item['ts'] < self.ttl:
                return item['data']
        return None

    def _update_cache(self, symbol, data_type, data):
        if symbol not in self._cache:
            self._cache[symbol] = {}
        self._cache[symbol][data_type] = {
            'data': data,
            'ts': time.time()
        }

    def batch_fetch_all(self, symbol_list):
        """æ‰¹é‡è·å–æ•°æ® (æ ¸å¿ƒä¼˜åŒ–)"""
        if not symbol_list: return

        unique_symbols = list(set([s.upper().strip() for s in symbol_list]))
        logger.info(f"ğŸ”„ æ­£åœ¨æ‰¹é‡åˆ·æ–°æ•°æ® ({len(unique_symbols)} æ”¯è‚¡ç¥¨)...")

        # 1. æ‰¹é‡ Quote
        try:
            briefs = self.client.get_stock_briefs(symbols=unique_symbols)
            for item in briefs:
                sym = getattr(item, 'symbol', None) or getattr(item, 'identifier', None)
                if sym: self._update_cache(sym, 'quote', item)
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡è¡Œæƒ…å¤±è´¥: {e}")

        # 2. æ‰¹é‡ Kçº¿ (5m & 4h)
        for period in ['5min', '240min']:
            try:
                bars_df = self.client.get_bars(
                    symbols=unique_symbols,
                    period=period,
                    limit=100,
                    right=QuoteRight.BR
                )
                if bars_df is not None and not bars_df.empty:
                    grouped = bars_df.groupby('symbol')
                    for sym, group in grouped:
                        # âš ï¸ å…³é”®: ç¡®ä¿æŒ‰æ—¶é—´æ­£åºæ’åˆ— (æ—§->æ–°)
                        df_clean = group.copy().sort_values('time')
                        df_clean.rename(columns={
                            'time': 'Datetime', 'open': 'Open', 'high': 'High',
                            'low': 'Low', 'close': 'Close', 'volume': 'Volume'
                        }, inplace=True)
                        self._update_cache(sym, period, df_clean)
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡ {period} Kçº¿å¤±è´¥: {e}")

    def get_realtime_snapshot(self, symbol):
        """è·å–å®æ—¶å¿«ç…§ (Mid-price & OI)"""
        cached = self._get_from_cache(symbol, 'quote')
        if not cached:
            try:
                self.batch_fetch_all([symbol])
                cached = self._get_from_cache(symbol, 'quote')
            except: pass
        
        if cached:
            bid = getattr(cached, 'bid_price', 0)
            ask = getattr(cached, 'ask_price', 0)
            latest = getattr(cached, 'latest_price', 0)
            mid = latest
            if bid and ask and bid > 0 and ask > 0:
                mid = (bid + ask) / 2
            return {'mid_price': mid, 'open_interest': getattr(cached, 'open_int', None)}
        return {}

    def get_bars(self, symbol, period):
        """è·å– K çº¿"""
        cached = self._get_from_cache(symbol, period)
        if cached is not None: return cached
        try:
            self.batch_fetch_all([symbol])
            return self._get_from_cache(symbol, period)
        except: return None

# ================= 4. è¾…åŠ©å‡½æ•° =================

def _get_private_key_path():
    import tempfile
    private_key_path = config.TIGER_PRIVATE_KEY
    is_key_content = (private_key_path and not private_key_path.endswith('.pem') and len(private_key_path) > 100)
    if is_key_content:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.pem', delete=False) as f:
            f.write(private_key_path)
            private_key_path = f.name
    return private_key_path

def _parse_json_response(ai_text):
    json_patterns = [r'JSON_SUMMARY\s*[:ï¼š]\s*({.*?})', r'```json\s*({.*?})\s*```', r'(\{[^{}]*"action"[^{}]*\})']
    for pattern in json_patterns:
        json_match = re.search(pattern, ai_text, re.DOTALL)
        if json_match:
            try: return json.loads(json_match.group(1))
            except: pass
    return {}

def init_services():
    global tiger_client, tiger_trade_client, deepseek_client, data_manager
    print("â³ åˆå§‹åŒ–æœåŠ¡...")
    try:
        deepseek_client = OpenAI(api_key=config.DEEPSEEK_API_KEY, base_url=getattr(config, 'DEEPSEEK_BASE_URL', "https://api.deepseek.com"))
    except Exception as e: logger.critical(f"âŒ DeepSeek å¤±è´¥: {e}"); sys.exit(1)

    try:
        client_config = TigerOpenClientConfig(sandbox_debug=config.IS_SANDBOX)
        client_config.private_key = read_private_key(_get_private_key_path())
        client_config.tiger_id = config.TIGER_ID
        client_config.account = config.TIGER_ACCOUNT
        client_config.language = Language.zh_CN 
        tiger_client = QuoteClient(client_config)
        tiger_trade_client = TradeClient(client_config)
        data_manager = MarketDataManager(tiger_client, ttl_seconds=60)
        logger.info(f"âœ… æœåŠ¡å°±ç»ª")
    except Exception as e: logger.critical(f"âŒ Tiger åˆå§‹åŒ–å¤±è´¥: {e}"); sys.exit(1)

def get_stock_name(symbol):
    try:
        contracts = tiger_trade_client.get_contracts(symbol=[symbol])
        if contracts: return contracts[0].name
    except: pass
    return symbol

def send_telegram(msg):
    if not getattr(config, 'TG_BOT_TOKEN', None): return
    try:
        requests.post(f"https://api.telegram.org/bot{config.TG_BOT_TOKEN}/sendMessage", 
                     json={"chat_id": config.TG_CHAT_IDS[0], "text": msg}, 
                     proxies=getattr(config, 'PROXIES', None), timeout=5)
    except Exception as e: logger.error(f"TG Error: {e}")

# ================= 5. ä¸»é€»è¾‘ =================

def run_analysis(symbol, silent=False):
    symbol = symbol.upper().strip()
    clean_symbol = symbol.split('.')[0] if '.' in symbol else symbol
    stock_name = get_stock_name(clean_symbol)
    
    if not silent: logger.info(f"ğŸ” åˆ†æ: {stock_name} ({clean_symbol})")

    # 1. ä»ç¼“å­˜/API è·å–æ•°æ®
    quote_data = data_manager.get_realtime_snapshot(clean_symbol)
    df_5m = data_manager.get_bars(clean_symbol, '5min')
    df_4h = data_manager.get_bars(clean_symbol, '240min')
    
    if df_5m is None:
        if not silent: logger.warning(f"âš ï¸ {stock_name} ç¼ºå°‘ 5m æ•°æ®")
        return None

    try:
        # 2. å¤„ç†æ•°æ® (æ¸…æ´— & è¯­ä¹‰æ ‡ç­¾)
        data_dict = {'intraday': df_5m, 'longterm': df_4h}
        processor = MarketDataProcessor(data_dict, quote_data)
        data_json = processor.get_analysis_payload(symbol)
        
        # 3. AI åˆ†æ
        if not silent: logger.info(f"ğŸ§  å‘é€ç»™ DeepSeek...")
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"### DUAL TIMEFRAME MARKET DATA:\n{data_json}"}
            ],
            stream=False, temperature=0.2 
        )
        ai_text = response.choices[0].message.content
        
        # 4. ç»“æœå¤„ç†
        parsed_res = _parse_json_response(ai_text)
        if not silent:
            report = f"ğŸ¯ {stock_name} ({symbol}) åˆ†ææŠ¥å‘Š\n"
            report += f"æ“ä½œ: {parsed_res.get('action', 'WAIT')}\nä¿¡åº¦: {parsed_res.get('confidence', 0)}%\n\n"
            report += f"è¯¦æƒ…:\n{ai_text[:1200]}..."
            send_telegram(report)
        return parsed_res

    except Exception as e:
        logger.error(f"âŒ æµç¨‹å¼‚å¸¸: {e}")
        return None

# ================= 6. å…¥å£ =================

def handle_command(cmd):
    global WATCH_LIST
    cmd = cmd.strip().upper()
    if cmd.startswith("/TRACK"):
        parts = cmd.split()
        if len(parts) > 1:
            WATCH_LIST = list(set(parts[1:]))
            return f"âœ… åˆ—è¡¨æ›´æ–°: {WATCH_LIST}"
    elif cmd == "/CLEAR":
        WATCH_LIST = []; return "âœ… åˆ—è¡¨å·²æ¸…ç©º"
    return None

def poll_telegram_updates():
    global LAST_UPDATE_ID
    if not getattr(config, 'TG_BOT_TOKEN', None): time.sleep(10); return
    try:
        resp = requests.get(f"https://api.telegram.org/bot{config.TG_BOT_TOKEN}/getUpdates", 
                          params={"offset": LAST_UPDATE_ID + 1, "timeout": 1}, 
                          proxies=getattr(config, 'PROXIES', None), timeout=5)
        data = resp.json()
        if data.get("ok") and data.get("result"):
            for item in data["result"]:
                LAST_UPDATE_ID = item["update_id"]
                text = item.get("message", {}).get("text", "")
                if text.startswith("/"):
                    reply = handle_command(text)
                    if reply: 
                        send_telegram(reply)
                        if WATCH_LIST:
                            data_manager.batch_fetch_all(WATCH_LIST)
                            for s in WATCH_LIST: run_analysis(s)
    except Exception: time.sleep(5)

if __name__ == "__main__":
    init_services()
    logger.info("ğŸš€ æœºå™¨äººå¯åŠ¨ (v3.0 è¯­ä¹‰å¢å¼ºç‰ˆ)")
    send_telegram("ğŸš€ æœºå™¨äººå·²é‡å¯: åŒå‘¨æœŸ + è¯­ä¹‰å¢å¼º + æ•°æ®æ¸…æ´—")
    while True: poll_telegram_updates(); time.sleep(1)